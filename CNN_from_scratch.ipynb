{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17478,"status":"ok","timestamp":1694519371453,"user":{"displayName":"ADELMO BRUNELLI","userId":"09889843803105275399"},"user_tz":-120},"id":"l-yPrqnhhOcz","outputId":"fd6a4314-dcd8-4bb7-eb38-40a9892a9d83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import json\n","import pandas as pd\n","import pathlib\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":339,"status":"ok","timestamp":1694696052022,"user":{"displayName":"ADELMO BRUNELLI","userId":"09889843803105275399"},"user_tz":-120},"id":"uVfJSGxAheCv","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"56c4eac7-4e3a-49c7-b10a-b531b13eb0d2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nCreated on Sat May 27 15:33:55 2023\\n\\n@author: adelmobrunelli\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from tqdm import tqdm\n","import tensorflow as tf"]},{"cell_type":"code","source":["# Set TensorFlow seed\n","tf.random.set_seed(42)\n","\n","# Set Numpy seed\n","np.random.seed(42)\n","\n","# Set Python seed\n","random.seed(42)\n","\n","# Set TensorFlow and Keras seed for reproducibility\n","tf.random.set_seed(42)"],"metadata":{"id":"MEZQreTvJiAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/My Drive/dataset.csv')\n","df.columns\n","\n","\n","# Check if any value is equal to 1\n","colonne_con_valore_1 = (df == 1).any()\n","\n","# Selects only columns that have at least one value equal to 1\n","colonne_selezionate = df.loc[:, colonne_con_valore_1]\n","\n","# Add the last column of the original DataFrame to the selected columns\n","colonne_selezionate[df.columns[-1]] = df[df.columns[-1]]\n","\n","df = colonne_selezionate\n","\n","print(df.columns)\n","\n","df = df.iloc[0:6000]\n","\n","SIZE = 244\n","X_dataset = []\n","\n","for i in tqdm(range(df.shape[0])):\n","    img = image.load_img(df.loc[i, 'ImageID'], target_size=(SIZE, SIZE, 3))\n","    img = image.img_to_array(img)\n","    img = img/255.\n","    X_dataset.append(img)\n","\n","X = np.array(X_dataset)\n","\n","y = np.array(df.drop(['ImageID'], axis=1))\n","\n","# Divide the dataset into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Divide the training set into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","# Print the size of the resulting datasets\n","print(\"Dimensioni set di addestramento:\", X_train.shape, y_train.shape)\n","print(\"Dimensioni set di test:\", X_test.shape, y_test.shape)\n","print(\"Dimensioni set di validazione:\", X_val.shape, y_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZ4ILRnqJkVz","executionInfo":{"status":"ok","timestamp":1694518782156,"user_tz":-120,"elapsed":561554,"user":{"displayName":"ADELMO BRUNELLI","userId":"09889843803105275399"}},"outputId":"7c8f250d-c768-45bc-fd3e-9704d4087c65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-0e26c418cbf6>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  colonne_selezionate[df.columns[-1]] = df[df.columns[-1]]\n"]},{"output_type":"stream","name":"stdout","text":["Index(['33', '34', '35', '36', '37', '38', '39', '40', '161', '162', '163',\n","       '164', '165', '167', '168', 'ImageID'],\n","      dtype='object')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [09:03<00:00,  5.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Dimensioni set di addestramento: (1920, 244, 244, 3) (1920, 15)\n","Dimensioni set di test: (600, 244, 244, 3) (600, 15)\n","Dimensioni set di validazione: (480, 244, 244, 3) (480, 15)\n"]}]},{"cell_type":"markdown","source":["\n","Experiment 1: one dense layer with 256 neurons and one dropout\n","\n","We try a simple model with a single dense layer of 256 neurons and dropout to fight the high overfitting.\n"],"metadata":{"id":"Jp7airanwjaZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ko6xjz6G4CE5"},"outputs":[],"source":["def lossAndAccuracy():\n","    #plot the training and validation accuracy and loss at each epoch\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(1, len(loss) + 1)\n","    plt.plot(epochs, loss, 'bo', label='Training loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","    plt.plot(epochs, acc, 'bo', label='Training acc')\n","    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","    plt.title('Training and validation accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n","\n","def precisionAndRecall():\n","    columnValues = [0, 1, 17, 33, 161, 34, 162, 35, 163, 36, 164, 37, 165, 38, 166,\n","                    39, 167, 40, 168, 49, 50, 65, 66, 67, 81, 82, 83, 84, 85, 86, 97,\n","                    98, 99, 100, 113, 255]\n","\n","    y_pred = model.predict(X_test)\n","\n","    threshold = 0.5\n","    y_pred_binary = (y_pred > threshold).astype(int)\n","\n","    from sklearn.metrics import precision_score, recall_score\n","    precision = precision_score(y_test, y_pred_binary, average='micro')\n","    recall = recall_score(y_test, y_pred_binary, average='micro')\n","\n","def checkLabelsItem(row_index):\n","    # Seleziona la riga e identifica gli indici dei valori a 1\n","    indices = df.loc[row_index, df.loc[row_index] == 1].index\n","\n","    # Stampa gli indici dei valori a 1\n","    print(\"Valori a 1 nella riga\", 1, \":\")\n","    print(indices)\n","\n","\n","from sklearn.metrics import roc_curve, auc, accuracy_score\n","\n","def show_precision_and_roc(model, test_data, test_labels):\n","    \"\"\"\n","    Mostra la precisione e la curva ROC di una rete convoluzionale.\n","\n","    Parametri:\n","    model: Il modello di rete convoluzionale già addestrato.\n","    test_data: Dati di test per valutare il modello.\n","    test_labels: Etichette corrispondenti ai dati di test.\n","\n","    \"\"\"\n","    # Calcola le predizioni del modello sui dati di test\n","    predictions = model.predict(test_data)\n","\n","    # Calcola la precisione\n","    accuracy = accuracy_score(test_labels.argmax(axis=1), predictions.argmax(axis=1))\n","    print(f\"Precisione: {accuracy:.2f}\")\n","\n","    # Calcola la curva ROC per ogni classe\n","    num_classes = test_labels.shape[1]\n","    fpr = {}\n","    tpr = {}\n","    roc_auc = {}\n","\n","    for i in range(num_classes):\n","        fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], predictions[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","    # Calcola la media delle curve ROC per ottenere la curva ROC media\n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(num_classes):\n","        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= num_classes\n","\n","    # Calcola l'AUC della curva ROC media\n","    mean_auc = auc(all_fpr, mean_tpr)\n","\n","    # Mostra i risultati\n","    plt.figure()\n","    plt.plot(all_fpr, mean_tpr, color='b', label=f'Media ROC (area = {mean_auc:.2f})')\n","    for i in range(num_classes):\n","        plt.plot(fpr[i], tpr[i], lw=1, label=f'Classe {i} (area = {roc_auc[i]:.2f})')\n","    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Curva ROC')\n","    plt.legend(loc='lower right')\n","    plt.grid(True)\n","    plt.show()\n","\n","\n","from sklearn.metrics import f1_score\n","\n","def calculate_f1_score(model, test_data, test_labels):\n","    \"\"\"\n","    Calcola l'F1-score di una rete convoluzionale per una classificazione multi-classe.\n","\n","    Parametri:\n","    model: Il modello di rete convoluzionale già addestrato.\n","    test_data: Dati di test per valutare il modello.\n","    test_labels: Etichette corrispondenti ai dati di test.\n","\n","    Restituisce:\n","    f1_score: L'F1-score calcolato.\n","    \"\"\"\n","\n","    # Calcola le predizioni del modello sui dati di test\n","    predictions = model.predict(test_data)\n","\n","    # Calcola l'F1-score\n","    f1_score_value = f1_score(test_labels.argmax(axis=1), predictions.argmax(axis=1), average='weighted')\n","\n","    return f1_score_value"]},{"cell_type":"code","source":["\"\"\"\n","Experiment 1:  one dense layer with 256 neurons\n","\n","\"\"\"\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(SIZE, SIZE, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=256, kernel_size=(5, 5), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(15, activation='sigmoid'))\n","\n","model.summary()\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train,\n","                    epochs=25,\n","                    batch_size=32,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEnAboYvPcoa","executionInfo":{"status":"ok","timestamp":1694523138516,"user_tz":-120,"elapsed":2956036,"user":{"displayName":"ADELMO BRUNELLI","userId":"09889843803105275399"}},"outputId":"fe720d0c-d0be-48d4-cb53-e9e1218869d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 240, 240, 16)      1216      \n","                                                                 \n"," batch_normalization (Batch  (None, 240, 240, 16)      64        \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 120, 120, 16)      0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 120, 120, 16)      0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 116, 116, 32)      12832     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 58, 58, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 58, 58, 32)        128       \n"," chNormalization)                                                \n","                                                                 \n"," dropout_1 (Dropout)         (None, 58, 58, 32)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 54, 54, 64)        51264     \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 27, 27, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 27, 27, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," dropout_2 (Dropout)         (None, 27, 27, 64)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 46656)             0         \n","                                                                 \n"," dense (Dense)               (None, 256)               11944192  \n","                                                                 \n"," dropout_3 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 15)                3855      \n","                                                                 \n","=================================================================\n","Total params: 12013807 (45.83 MB)\n","Trainable params: 12013583 (45.83 MB)\n","Non-trainable params: 224 (896.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","60/60 [==============================] - 295s 5s/step - loss: 0.6112 - accuracy: 0.1219 - val_loss: 0.3302 - val_accuracy: 0.0000e+00\n","Epoch 2/10\n","60/60 [==============================] - 296s 5s/step - loss: 0.2868 - accuracy: 0.0828 - val_loss: 0.4019 - val_accuracy: 0.0000e+00\n","Epoch 3/10\n","60/60 [==============================] - 296s 5s/step - loss: 0.2384 - accuracy: 0.0870 - val_loss: 0.3780 - val_accuracy: 0.6521\n","Epoch 4/10\n","60/60 [==============================] - 300s 5s/step - loss: 0.2219 - accuracy: 0.1109 - val_loss: 0.3527 - val_accuracy: 0.9979\n","Epoch 5/10\n","60/60 [==============================] - 299s 5s/step - loss: 0.1997 - accuracy: 0.1333 - val_loss: 0.3720 - val_accuracy: 1.0000\n","Epoch 6/10\n","60/60 [==============================] - 291s 5s/step - loss: 0.1836 - accuracy: 0.1568 - val_loss: 0.3969 - val_accuracy: 1.0000\n","Epoch 7/10\n","60/60 [==============================] - 293s 5s/step - loss: 0.1783 - accuracy: 0.1656 - val_loss: 0.2949 - val_accuracy: 0.8521\n","Epoch 8/10\n","60/60 [==============================] - 288s 5s/step - loss: 0.1782 - accuracy: 0.1542 - val_loss: 0.2334 - val_accuracy: 0.2833\n","Epoch 9/10\n","60/60 [==============================] - 295s 5s/step - loss: 0.1639 - accuracy: 0.1240 - val_loss: 0.2059 - val_accuracy: 0.1667\n","Epoch 10/10\n","60/60 [==============================] - 293s 5s/step - loss: 0.1583 - accuracy: 0.1302 - val_loss: 0.1920 - val_accuracy: 0.5208\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Experiment 2:  two dense layer 256/128 neurons and two dropout\n","\"\"\"\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(SIZE, SIZE, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=256, kernel_size=(5, 5), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(15, activation='sigmoid'))\n","\n","model.summary()\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train,\n","                    epochs=25,\n","                    batch_size=32,\n","                    validation_data=(X_val, y_val))\n","\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)\n","\n","y_pred = model.predict(X_test)\n","f1 = f1_score(y_test, y_pred.argmax(axis=1), average='weighted')"],"metadata":{"id":"xGEsoHuHYOrm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Experiment 3:  one dense layer and two dropout\n","\n","\"\"\"\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(SIZE, SIZE, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=256, kernel_size=(5, 5), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dropout(0.5))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(15, activation='sigmoid'))\n","\n","model.summary()\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train,\n","                    epochs=25,\n","                    batch_size=32,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)"],"metadata":{"id":"uDvDXLX0PgUg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Experiment 4: two dense layer with 256 neurons\n","\"\"\"\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(SIZE, SIZE, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=256, kernel_size=(5, 5), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","\n","model.add(Dense(15, activation='sigmoid'))\n","\n","model.summary()\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train,\n","                    epochs=25,\n","                    batch_size=32,\n","                    validation_data=(X_val, y_val))\n","\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)\n","\n","y_pred = model.predict(X_test)\n","f1 = f1_score(y_test, y_pred.argmax(axis=1), average='weighted')\n","\n","\n","print(f\"F1-Score: {f1:.2f}\")"],"metadata":{"id":"Ihf-QhjTPiHP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Experiment 5: two dense layer with 128/256 neurons\n","\"\"\"\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(SIZE, SIZE, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(filters=256, kernel_size=(5, 5), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","\n","model.add(Dense(15, activation='sigmoid'))\n","\n","model.summary()\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train,\n","                    epochs=25,\n","                    batch_size=32,\n","                    validation_data=(X_val, y_val))\n","\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)\n","\n","y_pred = model.predict(X_test)\n","f1 = f1_score(y_test, y_pred.argmax(axis=1), average='weighted')\n","\n","\n","print(f\"F1-Score: {f1:.2f}\")"],"metadata":{"id":"2u80wMgJPk7D"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOcIrjZCBAGSRqtivEnhKSl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}