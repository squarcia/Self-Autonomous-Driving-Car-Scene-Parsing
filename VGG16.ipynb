{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPSyCa0l4wnqvEuxsPv0dPm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iqd-DntTJO_d","executionInfo":{"status":"ok","timestamp":1694521181425,"user_tz":-120,"elapsed":4364,"user":{"displayName":"ADELMO BRUNELLI","userId":"09889843803105275399"}},"outputId":"6b7d51c5-8aea-46ed-e633-6e472ec3e65e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import json\n","import pandas as pd\n","import pathlib\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers, models\n","\n","import random\n","import numpy as np\n","\n","from tensorflow.keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from tqdm import tqdm\n","\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_curve, auc, accuracy_score\n"],"metadata":{"id":"tQvI8pG1VIpg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set TensorFlow seed\n","tf.random.set_seed(42)\n","\n","# Set Numpy seed\n","np.random.seed(42)\n","\n","# Set Python seed\n","random.seed(42)\n","\n","# Set TensorFlow and Keras seed for reproducibility\n","tf.random.set_seed(42)"],"metadata":{"id":"MEZQreTvJiAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/My Drive/dataset.csv')\n","df.columns\n","\n","\n","# Check if any value is equal to 1\n","colonne_con_valore_1 = (df == 1).any()\n","\n","# Selects only columns that have at least one value equal to 1\n","colonne_selezionate = df.loc[:, colonne_con_valore_1]\n","\n","# Add the last column of the original DataFrame to the selected columns\n","colonne_selezionate[df.columns[-1]] = df[df.columns[-1]]\n","\n","df = colonne_selezionate\n","\n","print(df.columns)\n","\n","df = df.iloc[0:6000]\n","\n","SIZE = 244\n","X_dataset = []\n","\n","for i in tqdm(range(df.shape[0])):\n","    img = image.load_img(df.loc[i, 'ImageID'], target_size=(SIZE, SIZE, 3))\n","    img = image.img_to_array(img)\n","    img = img/255.\n","    X_dataset.append(img)\n","\n","X = np.array(X_dataset)\n","\n","y = np.array(df.drop(['ImageID'], axis=1))\n","\n","# Divide the dataset into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Divide the training set into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","# Print the size of the resulting datasets\n","print(\"Dimensioni set di addestramento:\", X_train.shape, y_train.shape)\n","print(\"Dimensioni set di test:\", X_test.shape, y_test.shape)\n","print(\"Dimensioni set di validazione:\", X_val.shape, y_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZ4ILRnqJkVz","executionInfo":{"status":"ok","timestamp":1694518782156,"user_tz":-120,"elapsed":561554,"user":{"displayName":"ADELMO BRUNELLI","userId":"09889843803105275399"}},"outputId":"7c8f250d-c768-45bc-fd3e-9704d4087c65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-0e26c418cbf6>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  colonne_selezionate[df.columns[-1]] = df[df.columns[-1]]\n"]},{"output_type":"stream","name":"stdout","text":["Index(['33', '34', '35', '36', '37', '38', '39', '40', '161', '162', '163',\n","       '164', '165', '167', '168', 'ImageID'],\n","      dtype='object')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3000/3000 [09:03<00:00,  5.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Dimensioni set di addestramento: (1920, 244, 244, 3) (1920, 15)\n","Dimensioni set di test: (600, 244, 244, 3) (600, 15)\n","Dimensioni set di validazione: (480, 244, 244, 3) (480, 15)\n"]}]},{"cell_type":"code","source":["def lossAndAccuracy():\n","    #plot the training and validation accuracy and loss at each epoch\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(1, len(loss) + 1)\n","    plt.plot(epochs, loss, 'bo', label='Training loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","    plt.plot(epochs, acc, 'bo', label='Training acc')\n","    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","    plt.title('Training and validation accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n","\n","def precisionAndRecall():\n","    columnValues = [0, 1, 17, 33, 161, 34, 162, 35, 163, 36, 164, 37, 165, 38, 166,\n","                    39, 167, 40, 168, 49, 50, 65, 66, 67, 81, 82, 83, 84, 85, 86, 97,\n","                    98, 99, 100, 113, 255]\n","\n","    y_pred = model.predict(X_test)\n","\n","    threshold = 0.5\n","    y_pred_binary = (y_pred > threshold).astype(int)\n","\n","    from sklearn.metrics import precision_score, recall_score\n","    precision = precision_score(y_test, y_pred_binary, average='micro')\n","    recall = recall_score(y_test, y_pred_binary, average='micro')\n","\n","def checkLabelsItem(row_index):\n","    # Seleziona la riga e identifica gli indici dei valori a 1\n","    indices = df.loc[row_index, df.loc[row_index] == 1].index\n","\n","    # Stampa gli indici dei valori a 1\n","    print(\"Valori a 1 nella riga\", 1, \":\")\n","    print(indices)\n","\n","\n","def show_precision_and_roc(model, test_data, test_labels):\n","    \"\"\"\n","    Shows the accuracy and ROC curve of a convolutional network.\n","\n","    Parameters:\n","    model: The already trained convolutional network model.\n","    test_data: Test data to evaluate the model.\n","    test_labels: Labels corresponding to the test data.\n","\n","    \"\"\"\n","    # Calcola le predizioni del modello sui dati di test\n","    predictions = model.predict(test_data)\n","\n","    # Calcola la precisione\n","    accuracy = accuracy_score(test_labels.argmax(axis=1), predictions.argmax(axis=1))\n","    print(f\"Precisione: {accuracy:.2f}\")\n","\n","    # Calcola la curva ROC per ogni classe\n","    num_classes = test_labels.shape[1]\n","    fpr = {}\n","    tpr = {}\n","    roc_auc = {}\n","\n","    for i in range(num_classes):\n","        fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], predictions[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","    # Calcola la media delle curve ROC per ottenere la curva ROC media\n","    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n","    mean_tpr = np.zeros_like(all_fpr)\n","    for i in range(num_classes):\n","        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","    mean_tpr /= num_classes\n","\n","    # Calcola l'AUC della curva ROC media\n","    mean_auc = auc(all_fpr, mean_tpr)\n","\n","    # Mostra i risultati\n","    plt.figure()\n","    plt.plot(all_fpr, mean_tpr, color='b', label=f'Media ROC (area = {mean_auc:.2f})')\n","    for i in range(num_classes):\n","        plt.plot(fpr[i], tpr[i], lw=1, label=f'Classe {i} (area = {roc_auc[i]:.2f})')\n","    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Curva ROC')\n","    plt.legend(loc='lower right')\n","    plt.grid(True)\n","    plt.show()\n","\n","def calculate_f1_score(model, test_data, test_labels):\n","    \"\"\"\n","     Calculates the F1-score of a convolutional network for multi-class classification.\n","\n","    Parameters:\n","    model: The already trained convolutional network model.\n","    test_data: Test data to evaluate the model.\n","    test_labels: Labels corresponding to the test data.\n","\n","    Returns:\n","    f1_score: The calculated F1-score.\n","    \"\"\"\n","\n","    predictions = model.predict(test_data)\n","\n","    f1_score_value = f1_score(test_labels.argmax(axis=1), predictions.argmax(axis=1), average='weighted')\n","\n","    return f1_score_value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06A6EyvJNBUi","outputId":"15f878bd-e02e-4c35-ae6b-311c153e623b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]}]},{"cell_type":"code","source":["\"\"\"\n","  Using a pre-trained Convolutional Neural Network (CNN)\n","  as a feature extractor in a deep learning model.\n","\"\"\"\n","\n","conv_base = keras.applications.vgg16.VGG16(\n","    weights=\"imagenet\",\n","    include_top=False,\n","    input_shape=(244,244,3)\n",")\n","\n","\n","conv_base.summary()\n","\n","conv_base.trainable = False"],"metadata":{"id":"kjJfn45nOuFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","    Experiment 1: one Dense layer with 256 neurons\n","\"\"\"\n","\n","inputs = keras.Input(shape=(244,244,3))\n","x = keras.applications.vgg16.preprocess_input(inputs)\n","x = conv_base(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(256)(x)\n","outputs = layers.Dense(15, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()\n","\n","epochs = 100\n","batch_size = 32\n","history = model.fit(X_train, y_train,\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)\n","\n","model.save('vgg16_256.h5')"],"metadata":{"id":"mFR0SvJOTK6e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","    Experiment 2: one Dense layer with 256 neurons and a dropout\n","\"\"\"\n","\n","inputs = keras.Input(shape=(244,244,3))\n","x = keras.applications.vgg16.preprocess_input(inputs)\n","x = conv_base(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(256)(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(15, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()\n","\n","\n","epochs = 100\n","batch_size = 32\n","history = model.fit(X_train, y_train,\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)\n","\n","\n","model.save('vgg16_256_dropout.h5')"],"metadata":{"id":"u3Hp1ruDOxjc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","    Experiment 3: one dense layer with 256 neurons\n","                  and a dropout and GlobalAveragePooling\n","\"\"\"\n","\n","\n","inputs = keras.Input(shape=(244,244,3))\n","x = keras.applications.vgg16.preprocess_input(inputs)\n","x = conv_base(x)\n","x = GlobalAveragePooling2D()(x)\n","outputs = layers.Dense(15, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","\n","model.summary()\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","epochs = 100\n","batch_size = 32\n","history = model.fit(X_train, y_train,\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)\n","\n","model.save('vgg16_256_dropout_glob_avg.h5')"],"metadata":{"id":"k4yvWOtrSpwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" Fine Tuning \"\"\"\n","vgg_ft_1_layer = models.load_model('vgg16_256_dropout.h5')\n","\n","for layer in vgg_ft_1_layer.get_layer('vgg16').layers:\n","    if layer.name in ('block5_conv3'):\n","        layer.trainable = True\n","    else:\n","        layer.trainable = False\n","\n","for i, layer in enumerate(vgg_ft_1_layer.get_layer('vgg16').layers):\n","    print(i, layer.name, layer.trainable)\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()\n","\n","epochs = 25\n","batch_size = 32\n","history = model.fit(X_train, y_train,\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)"],"metadata":{"id":"IXHw7uyrO6z5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","    Experiment 4: remove two blocks dropout model\n","\"\"\"\n","\n","vgg16_ft_1_block = models.load_model('vgg16_256_dropout.h5')\n","\n","# Set the granularity of freezing levels.\n","for layer in vgg16_ft_1_block.get_layer('vgg16').layers:\n","    if layer.name in ('block5_conv2', 'block5_conv3', 'block5_conv1'):\n","        layer.trainable = True\n","    else:\n","        layer.trainable = False\n","\n","model.summary()\n","\n","# Print the trainable status of the levels\n","for i, layer in enumerate(vgg16_ft_1_block.get_layer('vgg16').layers):\n","    print(i, layer.name, layer.trainable)\n","\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","epochs = 25\n","batch_size = 32\n","history = model.fit(X_train, y_train,\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)"],"metadata":{"id":"CCtauI92O8Xj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","    Experiment 4bis: remove two blocks dense model\n","\"\"\"\n","\n","vgg16_ft_1_block = models.load_model('vgg16_256.h5')\n","\n","\n","for layer in vgg16_ft_1_block.get_layer('vgg16').layers:\n","    if layer.name in ('block5_conv2', 'block5_conv3', 'block5_conv1', 'block4_conv3', 'block4_conv2', 'block4_conv1'):\n","        layer.trainable = True\n","    else:\n","        layer.trainable = False\n","\n","model.summary()\n","\n","\n","for i, layer in enumerate(vgg16_ft_1_block.get_layer('vgg16').layers):\n","    print(i, layer.name, layer.trainable)\n","\n","\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","epochs = 25\n","batch_size = 32\n","history = model.fit(X_train, y_train,\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)"],"metadata":{"id":"WPxewFvMO92f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" Unfreeze last block dropout \"\"\"\n","\n","vgg16_ft_1_block = models.load_model('vgg16_fine_tuned_last_layer_dropout.h5')\n","\n","for layer in vgg16_ft_1_block.get_layer('vgg16').layers:\n","    if layer.name in ('block5_conv2', 'block5_conv3', 'block5_conv1'):\n","        layer.trainable = True\n","    else:\n","        layer.trainable = False\n","\n","model.summary()\n","\n","for i, layer in enumerate(vgg16_ft_1_block.get_layer('vgg16').layers):\n","    print(i, layer.name, layer.trainable)\n","\n","model.compile(optimizer=Adam(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","epochs = 25\n","batch_size = 32\n","history = model.fit(X_train, y_train,\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    validation_data=(X_val, y_val))\n","\n","lossAndAccuracy()\n","show_precision_and_roc(model, X_test, y_test)"],"metadata":{"id":"ptddjkI6O_Oz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" Show Intermediate Activations of a VGG16 Model in Black and White \"\"\"\n","\n","# Load a pre-trained VGG16 model\n","model = keras.applications.VGG16(weights='imagenet', include_top=False)\n","\n","# Choose an image from your dataset\n","img_path = 'test2.jpg'\n","img = keras.preprocessing.image.load_img(img_path, target_size=(244, 244))\n","img = keras.preprocessing.image.img_to_array(img)\n","img = np.expand_dims(img, axis=0)\n","\n","# Get the intermediate layer outputs\n","layer_names = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3', 'block5_conv3']\n","intermediate_layer_model = keras.Model(inputs=model.input, outputs=[model.get_layer(name).output for name in layer_names])\n","\n","# Get the intermediate activations for the chosen image\n","intermediate_activations = intermediate_layer_model.predict(img)\n","\n","# Visualize the intermediate activations in black and white\n","for layer_name, activation in zip(layer_names, intermediate_activations):\n","    plt.figure()\n","    plt.imshow(activation[0, :, :, 0], cmap='viridis')  # Display the first channel of the activation in black and white\n","    plt.title(layer_name)\n","    plt.colorbar()\n","\n","plt.show()"],"metadata":{"id":"Jqg5w8oKQKgg"},"execution_count":null,"outputs":[]}]}